{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df=pd.read_csv(r'E:\\All_Python_Frameworks\\Pandas\\Forecast\\forecast_best2')\n",
    "df=pd.read_csv('../Forecast/forecast_best2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('DT',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "df.head()\n",
    "<h2 style=\"color:green;text-align:center;\">Sales </h2>\n",
    "<h2 style=\"color:purple;text-align:center;\"> FOR </h2>\n",
    " <h1 style=\"color:orange;text-align:center;\"> ПАХА </h1>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                 ТО_НДС\nDT                     \n2023-04-01  25169364.54\n2023-04-02  21521028.50\n2023-04-03  13814550.97\n2023-04-04  14480259.59\n2023-04-05  15476963.72",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ТО_НДС</th>\n    </tr>\n    <tr>\n      <th>DT</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2023-04-01</th>\n      <td>25169364.54</td>\n    </tr>\n    <tr>\n      <th>2023-04-02</th>\n      <td>21521028.50</td>\n    </tr>\n    <tr>\n      <th>2023-04-03</th>\n      <td>13814550.97</td>\n    </tr>\n    <tr>\n      <th>2023-04-04</th>\n      <td>14480259.59</td>\n    </tr>\n    <tr>\n      <th>2023-04-05</th>\n      <td>15476963.72</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:green;text-align:left;\">ЕЩЕ Продажи </h2>\n",
    "<h2 style=\"color:yellow;text-align:left;\"> FOR </h2>\n",
    " <h1 style=\"color:blue;text-align:left;\"> ПАХА БЕСТ </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Columns not found: 'sales'\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m store_sales\u001B[38;5;241m=\u001B[39m\u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroupby\u001B[49m\u001B[43m(\u001B[49m\u001B[43mby\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mDT\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msales\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39msum()\n\u001B[0;32m      2\u001B[0m store_sales\n",
      "File \u001B[1;32mE:\\All_Python_Frameworks\\Pandas\\venv\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:1773\u001B[0m, in \u001B[0;36mDataFrameGroupBy.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1766\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(key) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1767\u001B[0m     \u001B[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001B[39;00m\n\u001B[0;32m   1768\u001B[0m     \u001B[38;5;66;03m# valid syntax, so don't raise\u001B[39;00m\n\u001B[0;32m   1769\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1770\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot subset columns with a tuple with more than one element. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1771\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUse a list instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1772\u001B[0m     )\n\u001B[1;32m-> 1773\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getitem__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\All_Python_Frameworks\\Pandas\\venv\\lib\\site-packages\\pandas\\core\\base.py:239\u001B[0m, in \u001B[0;36mSelectionMixin.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    237\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mintersection(key)) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mset\u001B[39m(key)):\n\u001B[0;32m    238\u001B[0m         bad_keys \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mset\u001B[39m(key)\u001B[38;5;241m.\u001B[39mdifference(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39mcolumns))\n\u001B[1;32m--> 239\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumns not found: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(bad_keys)[\u001B[38;5;241m1\u001B[39m:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    240\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gotitem(\u001B[38;5;28mlist\u001B[39m(key), ndim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m    242\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mKeyError\u001B[0m: \"Columns not found: 'sales'\""
     ]
    }
   ],
   "source": [
    "store_sales=df.groupby(by='DT')[['sales']].sum()\n",
    "store_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store=store_sales.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(store_sales,color=store)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df[df.item==1][['sales']],labels=dict(value=\"Sales\"))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df[(df.item==1) & (df.store==4)][['sales']],y='sales')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict 3 months of sales for 50 different items at 10 different stores.\n",
    " <h1 style=\"color:orange;text-align:center;\"> ПАХА I NEED WORK </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_1=df[(df.item==1) & (df.store==1)][['sales']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_1_1)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationary\n",
    "mean,variance and co-variance is constant over periods\n",
    "<h2 style=\"color:red;text-align:LEFT;\"> ПАХА I STILL NEED WORK </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "result = seasonal_decompose(df_1_1, model='additive', period=365)\n",
    "plt.figure(figsize=(36, 24))\n",
    "result.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_1.iloc[1400:,].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(36,24))\n",
    "sm.graphics.tsa.plot_acf(df_1_1, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for stationary using Ad Fuller Hypothesis test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis of the test is that the time series can be represented by a unit root, that it is not stationary (has some time-dependent structure). The alternate hypothesis (rejecting the null hypothesis) is that the time series is stationary.\n",
    "\n",
    "<strong>Null Hypothesis (H0):</strong> If failed to be rejected, it suggests the time series has a unit root, meaning it is non-stationary. It has some time dependent structure.\n",
    "Alternate Hypothesis (H1): The null hypothesis is rejected; it suggests the time series does not have a unit root, meaning it is stationary. It does not have time-dependent structure.\n",
    "We interpret this result using the p-value from the test. A p-value below a threshold (such as 5% or 1%) suggests we reject the null hypothesis (stationary), otherwise a p-value above the threshold suggests we fail to reject the null hypothesis (non-stationary).\n",
    "\n",
    "<strong>p-value > 0.05:</strong> Fail to reject the null hypothesis (H0), the data has a unit root and is non-stationary.\n",
    "\n",
    "<strong>p-value <= 0.05:</strong> Reject the null hypothesis (H0), the data does not have a unit root and is stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "hypothesis_test=adfuller(df_1_1)\n",
    "print('ADF Statistic: %f' % hypothesis_test[0])\n",
    "print('p-value: %f' % hypothesis_test[1])\n",
    "print('Critical Values:')\n",
    "for key, value in hypothesis_test[4].items():\n",
    "    print('\\t%s: %.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The more negative this statistic, the more likely we are to reject the null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Histogram</center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_1_1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p<0.05 so we reject the null hypothesis and the Time series is Stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_1.diff(periods=1).fillna(0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff=df_1_1.diff(periods=1) #Integrated of order 1 denoted by d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff=df_diff[1:]\n",
    "df_diff.head()## 1 Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_diff)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "p=d=q=range(0,5)\n",
    "pdq =list(itertools.product(p,d,q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_1_1.values\n",
    "size = int(len(X) * 0.66)\n",
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_1_1.values\n",
    "size = int(len(X) * 0.88)\n",
    "train, test = X[0:size], X[size:len(X)]\n",
    "history = [x for x in train]\n",
    "predictions = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_date=df_1_1.index[0:size]\n",
    "test_date=df_1_1.index[size:len(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "AIC={}\n",
    "for i in pdq:\n",
    "    try:\n",
    "        model_arima=ARIMA(train,order=(i))\n",
    "        model_fit=model_arima.fit()\n",
    "        print(model_fit.aic,\" \",i)\n",
    "        AIC[model_fit.aic]=i\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC[min(AIC.keys())] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arima=ARIMA(train,order=(2,1,3))\n",
    "model_fit=model_arima.fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the parameter (p,d,q) -> (4,3,2) as it has minimum AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals=pd.DataFrame(model_fit.resid)\n",
    "residuals.plot()\n",
    "print(residuals.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "# walk-forward validation\n",
    "for t in range(len(test)):\n",
    "\tmodel = ARIMA(history, order=(2,1,3))\n",
    "\tmodel_fit = model.fit()\n",
    "\toutput = model_fit.forecast()\n",
    "\tyhat = output[0]\n",
    "\tpredictions.append(yhat)\n",
    "\tobs = test[t]\n",
    "\thistory.append(obs)\n",
    "\tprint('predicted=%f, expected=%f' % (yhat, obs))\n",
    "# evaluate forecasts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = np.sqrt(mean_squared_error(test, predictions))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "# plot forecasts against actual outcomes\n",
    "plt.figure(figsize=(24,12))\n",
    "plt.plot(test)\n",
    "plt.plot(predictions, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "print('Mean Absolute Error:',mean_absolute_error(test.reshape(-1),predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(350,200))\n",
    "plt.plot(train_date[1600:],train[1600:],'green')\n",
    "plt.plot(test_date,test,'blue')\n",
    "plt.plot(test_date,predictions,'red')\n",
    "plt.savefig('A.png')\n",
    "plt.xticks(rotation = 90,fontsize=150)\n",
    "plt.xlabel('Date', fontsize=250)\n",
    "plt.ylabel('Sales', fontsize=250)\n",
    "plt.savefig('Arima.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = px.line(train_date,train)\n",
    "#fig.show()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred=pd.DataFrame({'Predictions':predictions},index=test_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_1_1.merge(df_pred,'inner',on='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
